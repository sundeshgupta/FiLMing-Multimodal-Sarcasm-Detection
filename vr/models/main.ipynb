{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.plot = False\n",
    "        self.eager = False\n",
    "        self.mf = 'model.jpg'\n",
    "        self.tf = 'main-out.txt'\n",
    "        self.pf = 'training-plot.jpg'\n",
    "        self.pt = 'Training Multimodal'\n",
    "        self.data_ready = True\n",
    "        self.epochs = 20\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZG-EXTkSl8pk"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApeMkf5Ql8pl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCAqWchVl8pZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-cb04eb8dfa06>:1: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(args.eager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-wNaKzIl8po"
   },
   "source": [
    "## directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eihaI6Qbz-0A"
   },
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3EPIp2-088h"
   },
   "outputs": [],
   "source": [
    "def create_dict(keys, val1s, val2s =None, val3s = None, top = False):\n",
    "    temp = {}\n",
    "    if (top):\n",
    "        for key, val in zip(keys, val1s):\n",
    "            temp[str(key)] = val\n",
    "    else:\n",
    "        for key, val1, val2 in zip(keys, val1s, val2s):\n",
    "            temp[str(key)] = {\n",
    "                'text':np.array(val1),\n",
    "                'top':np.array(val3s[str(key)]),\n",
    "                'label':int(val2)\n",
    "            }\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7isWBMTz9Ms"
   },
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    with open(filename, 'rb') as filehandle:\n",
    "        ret = pickle.load(filehandle)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, obj):\n",
    "    with open(filename, 'wb') as filehandle:\n",
    "        pickle.dump(obj, filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bv1f8I1b0Lev"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfVDgugh0Du2"
   },
   "source": [
    "### preprocessing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXkP-HWJl8px"
   },
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self, seq_len, batch_size, data_ready, img_path, img_vector):\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.image_top = None\n",
    "        self.data_ready = data_ready\n",
    "        self.img_path = img_path\n",
    "        self.img_vector = img_vector\n",
    "        self.resnet50 = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    def download(self):\n",
    "        url_img_dataset = 'https://www.dropbox.com/s/ofmxf7fxyixdw4a/dataset_image_all.zip?dl=1'\n",
    "        file_img_dataset = 'dataset_image_all.zip'\n",
    "        if not(self.data_ready):\n",
    "            tf.keras.utils.get_file(fname=file_img_dataset, origin=url_img_dataset, extract=True, cache_subdir=os.getcwd())\n",
    "        \n",
    "        url_dataset = 'https://www.dropbox.com/s/n5i5pid134v5rkj/twitter-multi-modal.zip?dl=1'\n",
    "        file_dataset = 'twitter-multi-modal.zip'\n",
    "        if not(self.data_ready):\n",
    "            tf.keras.utils.get_file(fname=file_dataset, origin=url_dataset, extract=True, cache_subdir=os.getcwd())\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpoUWX5o0bv-"
   },
   "source": [
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5multwDLl8p1"
   },
   "outputs": [],
   "source": [
    "pp = Preprocessor(30, 32, args.data_ready, 'temp', 'temp')\n",
    "pp.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b0xElDnDl8p_"
   },
   "outputs": [],
   "source": [
    "train_data = load_file('/home/sundesh/Documents/git/sarcasm/train_data')\n",
    "valid_data = load_file('/home/sundesh/Documents/git/sarcasm/valid_data')\n",
    "test_data = load_file('/home/sundesh/Documents/git/sarcasm/test_data')\n",
    "image_top = load_file('/home/sundesh/Documents/git/sarcasm/image_top')\n",
    "\n",
    "# # processing dataset for batch compatability\n",
    "# train_dataset = pp.prepare_dataset('train.csv')\n",
    "# valid_dataset = pp.prepare_dataset('valid.csv')\n",
    "# test_dataset = pp.prepare_dataset('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jvo84kFFl8qC"
   },
   "outputs": [],
   "source": [
    "train_text = [str(item['text']) for item in train_data.values()]\n",
    "valid_text = [str(item['text']) for item in valid_data.values()]\n",
    "test_text = [str(item['text']) for item in test_data.values()]\n",
    "top_text = [ \" \".join(item) for item in image_top.values()]\n",
    "\n",
    "train_labels = [int(item['label']) for item in train_data.values()]\n",
    "valid_labels = [int(item['label']) for item in valid_data.values()]\n",
    "test_labels = [int(item['label']) for item in test_data.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "famLiO5El8qF"
   },
   "outputs": [],
   "source": [
    "train_id = [str(item) for item in train_data.keys()]\n",
    "valid_id = [str(item) for item in valid_data.keys()]\n",
    "test_id = [str(item) for item in test_data.keys()]\n",
    "top_id = [ str(item) for item in image_top.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text, train_labels, train_id = shuffle(train_text, train_labels,train_id)\n",
    "# valid_text, valid_labels, valid_id = shuffle(valid_text, valid_labels,valid_id)\n",
    "# test_text, test_labels, test_id = shuffle(test_text, test_labels,test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19816 2409 2410\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels), len(test_labels), len(valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minimizing dataset for test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_text[:500]\n",
    "train_labels = train_labels[:500]\n",
    "train_id = train_id[:500]\n",
    "\n",
    "valid_text = valid_text[:250]\n",
    "valid_labels = valid_labels[:250]\n",
    "valid_id = valid_id[:250]\n",
    "\n",
    "test_text = test_text[:250]\n",
    "test_labels = test_labels[:250]\n",
    "test_id = test_id[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = load_file(\"/home/sundesh/Documents/git/sarcasm/temp/train_text\")\n",
    "train_labels = load_file(\"/home/sundesh/Documents/git/sarcasm/temp/train_labels\")\n",
    "train_id = load_file(\"/home/sundesh/Documents/git/sarcasm/temp/train_id\")\n",
    "\n",
    "# valid_text = load_file(\"./temp/valid_text\")\n",
    "# valid_labels = load_file(\"./temp/valid_labels\")\n",
    "# valid_id = load_file(\"./temp/valid_id\")\n",
    "\n",
    "# test_text = load_file(\"./temp/test_text\")\n",
    "# test_labels = load_file(\"./temp/test_labels\")\n",
    "# test_id = load_file(\"./temp/test_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "config = BertConfig()\n",
    "# for more information on what's happening under the hood\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "transform_pipe = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This is our custom dataset class which will load the images, perform transforms on them,\n",
    "    and load their corresponding labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, labels, text, filenames, transform=None):\n",
    "        \"\"\"\n",
    "        img_dir = dir in which images are located\n",
    "        labels = list containing true (0/1) values\n",
    "        text = list containing all the texts\n",
    "        filenames = list containing the names of images\n",
    "        transform = transformer to preprocess images\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = os.path.join(\n",
    "                self.img_dir,\n",
    "                \"{}.jpg\".format(self.filenames[idx])\n",
    "            )\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "                \n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        sample = {\n",
    "            \"image\": img,\n",
    "        }\n",
    "        \n",
    "        text = self.text[idx]\n",
    "        text = '[CLS] ' + text + ' [SEP]'\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        tokenized_text = tokenizer.tokenize(text)\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        while len(indexed_tokens) < 70:\n",
    "            indexed_tokens.append(0)\n",
    "        tokens_tensor = torch.tensor(indexed_tokens)\n",
    "        \n",
    "        try:\n",
    "            sample[\"label\"] = self.labels[idx]\n",
    "            sample[\"token\"] = tokens_tensor # torch.Size([batch_size, 512])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_object = TwitterDataset(\n",
    "    img_dir=\"./dataset_image/\",\n",
    "    labels = train_labels,\n",
    "    text = train_text,\n",
    "    filenames = train_id,\n",
    "    transform=transform_pipe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data_object,\n",
    "    batch_size=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'FiLMedNet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d9b237567760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mFiLMedNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFiLMGen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'FiLMedNet'"
     ]
    }
   ],
   "source": [
    "import FiLMedNet\n",
    "import FiLMGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2u2W_PfZl8qL",
    "29UQqeLil8qT",
    "8GVi5gcRl8qX",
    "pNzsGeeHl8qi",
    "0KPdOVWel8rj"
   ],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
